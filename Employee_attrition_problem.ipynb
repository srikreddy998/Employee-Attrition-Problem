{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Welcome to Jupyter!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "X = pd.read_csv(\"PS2_data.csv\")\n",
    "X.columns.values\n",
    "print(\"Data Type of the features: \\n\")\n",
    "print(X.dtypes)\n",
    "print('\\n')\n",
    "print(\"Check for any null/empty values in the features: \\n\")\n",
    "print(X.isnull().any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Dummy values for qualitative features \n",
    "\n",
    "qual_vars=['Department','salary']\n",
    "for var in qual_vars:\n",
    "    qual_list='var'+'_'+var\n",
    "    qual_list = pd.get_dummies(X[var], prefix=var)\n",
    "    X1=X.join(qual_list)\n",
    "    X=X1\n",
    "    \n",
    "X.drop(X.columns[[7, 8]], axis=1, inplace=True)\n",
    "X.columns.values    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "pos = X[X[\"Attrition\"] == 1].shape[0]\n",
    "neg = X[X[\"Attrition\"] == 0].shape[0]\n",
    "print(\"Positive examples = {}\".format(pos))\n",
    "print(\"Negative examples = {}\".format(neg))\n",
    "print(\"Proportion of positive to negative examples = {:.2f}%\".format((pos / neg) * 100))\n",
    "sns.countplot(X[\"Attrition\"])\n",
    "plt.xticks((0, 1), [\"Didn't leave\", \"Left\"])\n",
    "plt.xlabel(\"Left\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Class counts\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Split Data into two sets in the ratio of 80:20\n",
    "\n",
    "X_1 = X.loc[:, X.columns != \"Attrition\"].values\n",
    "y_1 = X.loc[:, X.columns == \"Attrition\"].values.flatten()\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_1, y_1, test_size=0.2, stratify=y_1, random_state=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Logistic Regression\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "X_tr_nor = normalize(X_train)\n",
    "X_ts_nor = normalize(X_test)\n",
    "\n",
    "X_tr_nor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "model = LogisticRegression(C=5000, solver = \"liblinear\").fit(X_tr_nor , y_train )\n",
    "y_pred= model.predict(X_ts_nor)\n",
    "print('Accuracy of Logistic Regression: {:.6f}' .format(accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## SVM accuracy\n",
    "from sklearn.svm import SVC\n",
    "model1= SVC(probability=True).fit(X_train, y_train)\n",
    "y_pred2 = model1.predict(X_test)\n",
    "print('Accuracy of Support Vector Machine: {:.6f}' .format(accuracy_score(y_test, y_pred2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Random Forest accuracy\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model2 = RandomForestClassifier().fit(X_train, y_train)\n",
    "y_pred3 = model2.predict(X_test)\n",
    "print('Accuracy of Random Forest Classifier: {:.6f}' .format(accuracy_score(y_test, y_pred3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Random Forest F1 score\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, model2.predict(X_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Logistic Regression F1 score\n",
    "print(classification_report(y_test, model.predict(X_ts_nor)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## SVM F1 score\n",
    "print(classification_report(y_test, model1.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "## cross validation for Random Forest 10 fold\n",
    "kfold = model_selection.KFold(n_splits=10, random_state=7)\n",
    "scoring = 'accuracy'\n",
    "results = model_selection.cross_val_score(model2, X_train, y_train, cv=kfold, scoring=scoring)\n",
    "print(\"10-fold cross validation average accuracy Random Forest: %.3f\" % (results.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_selection' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-2ce1012e9f83>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m## Logistic Regression crossvalidation 10 fold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mscoring\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_selection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_tr_nor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkfold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"10-fold cross validation average accuracy Logisitic Reggression: %.3f\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model_selection' is not defined"
     ]
    }
   ],
   "source": [
    "## Logistic Regression crossvalidation 10 fold\n",
    "scoring = 'accuracy'\n",
    "results = model_selection.cross_val_score(model, X_tr_nor, y_train, cv=kfold, scoring=scoring)\n",
    "print(\"10-fold cross validation average accuracy Logisitic Reggression: %.3f\" % (results.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## SVM crossvalidation 10 fold\n",
    "scoring = 'accuracy'\n",
    "results = model_selection.cross_val_score(model1, X_train, y_train, cv=kfold, scoring=scoring)\n",
    "print(\"10-fold cross validation average accuracy SVM: %.3f\" % (results.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Confusion Matrix of Logistic Regression Model\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "logreg_y_pred = model.predict(X_ts_nor)\n",
    "logreg_cm = metrics.confusion_matrix(logreg_y_pred, y_test, [1,0])\n",
    "sns.heatmap(logreg_cm, annot=True, fmt='.2f',xticklabels = [\"Left\", \"Stayed\"] , yticklabels = [\"Left\", \"Stayed\"] )\n",
    "plt.ylabel('True class')\n",
    "plt.xlabel('Predicted class')\n",
    "plt.title('Logistic Regression')\n",
    "plt.savefig('logistic_regression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Confusion matrix for SVM Model \n",
    "\n",
    "svm_y_pred = model1.predict(X_test)\n",
    "svm_cm = metrics.confusion_matrix(svm_y_pred, y_test, [1,0])\n",
    "sns.heatmap(svm_cm, annot=True, fmt='.2f',xticklabels = [\"Left\", \"Stayed\"] , yticklabels = [\"Left\", \"Stayed\"] )\n",
    "plt.ylabel('True class')\n",
    "plt.xlabel('Predicted class')\n",
    "plt.title('Support Vector Machine')\n",
    "plt.savefig('Support_Vector_Machine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Confusion Matrix for Random Forest model\n",
    "RF_y_pred = model2.predict(X_test)\n",
    "RF_cm = metrics.confusion_matrix(RF_y_pred, y_test, [1,0])\n",
    "sns.heatmap(RF_cm, annot=True, fmt='.2f',xticklabels = [\"Left\", \"Stayed\"] , yticklabels = [\"Left\", \"Stayed\"] )\n",
    "plt.ylabel('True class')\n",
    "plt.xlabel('Predicted class')\n",
    "plt.title('Random Forest Classification')\n",
    "plt.savefig('Random Forest Classification')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "logit_roc_auc = roc_auc_score(y_test, model.predict(X_test))\n",
    "fpr, tpr, thresholds = roc_curve(y_test, model.predict_proba(X_test)[:,1])\n",
    "\n",
    "\n",
    "rf_roc_auc = roc_auc_score(y_test, model2.predict(X_test))\n",
    "rf_fpr, rf_tpr, rf_thresholds = roc_curve(y_test, model2.predict_proba(X_test)[:,1])\n",
    "\n",
    "svm_roc_auc = roc_auc_score(y_test, model1.predict(X_test))\n",
    "s_fpr, s_tpr, s_thresholds = roc_curve(y_test, model1.predict_proba(X_test)[:,1])\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label='Logistic Regression (area = %0.2f)' % logit_roc_auc)\n",
    "plt.plot(rf_fpr, rf_tpr, label='Random Forest (area = %0.2f)' % rf_roc_auc)\n",
    "plt.plot(s_fpr, s_tpr, label='Support Vector Machine (area = %0.2f)' % svm_roc_auc)\n",
    "\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig('ROC')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This repo contains an introduction to [Jupyter](https://jupyter.org) and [IPython](https://ipython.org).\n",
    "\n",
    "Outline of some basics:\n",
    "\n",
    "* [Notebook Basics](../examples/Notebook/Notebook%20Basics.ipynb)\n",
    "* [IPython - beyond plain python](../examples/IPython%20Kernel/Beyond%20Plain%20Python.ipynb)\n",
    "* [Markdown Cells](../examples/Notebook/Working%20With%20Markdown%20Cells.ipynb)\n",
    "* [Rich Display System](../examples/IPython%20Kernel/Rich%20Output.ipynb)\n",
    "* [Custom Display logic](../examples/IPython%20Kernel/Custom%20Display%20Logic.ipynb)\n",
    "* [Running a Secure Public Notebook Server](../examples/Notebook/Running%20the%20Notebook%20Server.ipynb#Securing-the-notebook-server)\n",
    "* [How Jupyter works](../examples/Notebook/Multiple%20Languages%2C%20Frontends.ipynb) to run code in different languages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also get this tutorial and run it on your laptop:\n",
    "\n",
    "    git clone https://github.com/ipython/ipython-in-depth\n",
    "\n",
    "Install IPython and Jupyter:\n",
    "\n",
    "with [conda](https://www.anaconda.com/download):\n",
    "\n",
    "    conda install ipython jupyter\n",
    "\n",
    "with pip:\n",
    "\n",
    "    # first, always upgrade pip!\n",
    "    pip install --upgrade pip\n",
    "    pip install --upgrade ipython jupyter\n",
    "\n",
    "Start the notebook in the tutorial directory:\n",
    "\n",
    "    cd ipython-in-depth\n",
    "    jupyter notebook"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
